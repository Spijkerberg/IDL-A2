# -*- coding: utf-8 -*-
"""A2_group_45_FINAL_VERSION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YukRUDn3J1pSWV2NX3GI7cx3STv2HIbm

<div style="text-align: right">   </div>


Introduction to Deep Learning (2023) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp;
-------|-------------------
**Assignment 2 - Recurrent Neural Networks** | <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/UniversiteitLeidenLogo.svg/1280px-UniversiteitLeidenLogo.svg.png" width="300">



# Introduction


The goal of this assignment is to learn how to use encoder-decoder recurrent neural networks (RNNs). Specifically we will be dealing with a sequence to sequence problem and try to build recurrent models that can learn the principles behind simple arithmetic operations (**integer addition, subtraction and multiplication.**).

<img src="https://i.ibb.co/5Ky5pbk/Screenshot-2023-11-10-at-07-51-21.png" alt="Screenshot-2023-11-10-at-07-51-21" border="0" width="500"></a>

In this assignment you will be working with three different kinds of models, based on input/output data modalities:
1. **Text-to-text**: given a text query containing two integers and an operand between them (+ or -) the model's output should be a sequence of integers that match the actual arithmetic result of this operation
2. **Image-to-text**: same as above, except the query is specified as a sequence of images containing individual digits and an operand.
3. **Text-to-image**: the query is specified in text format as in the text-to-text model, however the model's output should be a sequence of images corresponding to the correct result.


### Description**
Let us suppose that we want to develop a neural network that learns how to add or subtract two integers that are at most two digits long.

For example, given input strings of 5 characters: ‘81+24’ or’41-89’ that consist of 2 two-digit long integers and an operand between them, the network should return a sequence of 3 characters: ‘105 ’ or ’-48 ’ that represent the result of their respective queries.

Additionally, we want to build a model that generalizes well - if the network can extract the underlying principles behind the ’+’ and ’-’ operands and associated operations, it should not need too many training examples to generate
valid answers to unseen queries.

To represent such queries we need 13 unique characters: 10 for digits (0-9),
2 for the ’+’ and ’-’ operands and one for whitespaces ’ ’ used as padding.

The example above describes a text-to-text sequence mapping scenario. However, we can also use different
modalities of data to represent our queries or answers. For that purpose, the MNIST handwritten digit
dataset is going to be used again, however in a slightly different format. The functions below will be used to create our datasets.

---

*To work on this notebook you should create a copy of it.*

## Function definitions for creating the datasets

First we need to create our datasets that are going to be used for training our models.

In order to create image queries of simple arithmetic operations such as '15+13' or '42-10' we need to create images of '+' and '-' signs using ***open-cv*** library. We will use these operand signs together with the MNIST dataset to represent the digits.
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
import numpy as np
import time
import random
from sklearn.model_selection import train_test_split
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, RNN, LSTM, Flatten, TimeDistributed, LSTMCell, Dropout
from tensorflow.keras.layers import RepeatVector, Conv2D, SimpleRNN, GRU, Reshape, ConvLSTM2D, Conv2DTranspose
from tensorflow.keras.layers import BatchNormalization, MaxPooling3D, MaxPooling2D
from scipy.ndimage import rotate
from tensorflow import keras
from google.colab import drive
import pandas as pd
from scipy.stats import mode

# This is the TPU initialization code that has to be at the beginning.
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
print("All devices:", *tf.config.list_logical_devices('TPU'), sep='\n\t')

# Optimize TPU
strategy = tf.distribute.TPUStrategy(resolver)

"""Create +, - and * simulated images"""

# Create plus/minus operand signs
def generate_images(number_of_images=50, sign='-'):
    blank_images = np.zeros([number_of_images, 28, 28])  # Dimensionality matches the size of MNIST images (28x28)
    x = np.random.randint(12, 16, (number_of_images, 2)) # Randomized x coordinates
    y1 = np.random.randint(6, 10, number_of_images)       # Randomized y coordinates
    y2 = np.random.randint(18, 22, number_of_images)     # -||-
    for i in range(number_of_images): # Generate n different images
        cv2.line(blank_images[i], (y1[i], x[i,0]), (y2[i], x[i, 1]), (255,0,0), 2, cv2.LINE_AA)     # Draw line with randomized coordinates
        if sign == '+':
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw line with randomized coordinates
        if sign == '*': # consists of 3 lines which are rotated w.r.t. each other.
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw line with randomized coordinates
            # Rotate 45 degrees to create next lines
            blank_images[i] = rotate(blank_images[i], -50, reshape=False)
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw line with randomized coordinates
            blank_images[i] = rotate(blank_images[i], -50, reshape=False)
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw line with randomized coordinates
    return blank_images

def show_generated(images, n=5):
    plt.figure(figsize=(2, 2))
    for i in range(n**2):
        plt.subplot(n, n, i+1)
        plt.axis('off')
        plt.imshow(images[i])
    plt.show()

show_generated(generate_images(sign='-'))
show_generated(generate_images(sign='+'))
show_generated(generate_images(sign='*'))

"""## Creating our data

The dataset consists of 20000 samples that (additions and subtractions between all 2-digit integers) and they have two kinds of inputs and label modalities:

  **X_text**: strings containing queries of length 5: ['  1+1  ', '11-18', ...]

  **X_image**: a stack of images representing a single query, dimensions: [5, 28, 28]

  **y_text**: strings containing answers of length 3: ['  2', '156']

  **y_image**: a stack of images that represents the answer to a query, dimensions: [3, 28, 28]
"""

def create_data(highest_integer, num_addends=2, operands=['+', '-']):
    """
    Creates the following data for all pairs of integers up to [1->highest integer][+ or -][1->highest_integer]:

    @return:
    X_text: '51+21' -> text query of an arithmetic operation (5)
    X_img : Stack of MNIST images corresponding to the query (5 x 28 x 28) -> sequence of 5 images (one per number and operation, i.e. 51+21 is the sequence of 5 images) of size 28x28
    y_text: '72' -> answer of the arithmetic text query
    y_img :  Stack of MNIST images corresponding to the answer (3 x 28 x 28) (for negative numbers: '-xx', for positive smaller than 100: ' xx' (note the padding of ' '))

    Images for digits are picked randomly from the whole MNIST dataset.
    """

    num_indices = [np.where(MNIST_labels==x) for x in range(10)]
    num_data = [MNIST_data[inds] for inds in num_indices]
    image_mapping = dict(zip(unique_characters[:10], num_data))
    image_mapping['-'] = generate_images()
    image_mapping['+'] = generate_images(sign='+')
    image_mapping['*'] = generate_images(sign='*')
    image_mapping[' '] = np.zeros([1, 28, 28])

    X_text, X_img, y_text, y_img = [], [], [], []

    for i in range(highest_integer + 1):      # First addend
        for j in range(highest_integer + 1):  # Second addend
            for sign in operands: # Create all possible combinations of operands
                query_string = to_padded_chars(str(i) + sign + str(j), max_len=max_query_length, pad_right=True)
                query_image = []
                for n, char in enumerate(query_string):
                    image_set = image_mapping[char]
                    index = np.random.randint(0, len(image_set), 1)
                    query_image.append(image_set[index].squeeze())

                result = eval(query_string)
                result_string = to_padded_chars(result, max_len=max_answer_length, pad_right=True)
                result_image = []
                for n, char in enumerate(result_string):
                    image_set = image_mapping[char]
                    index = np.random.randint(0, len(image_set), 1)
                    result_image.append(image_set[index].squeeze())

                X_text.append(query_string)
                X_img.append(np.stack(query_image))
                y_text.append(result_string)
                y_img.append(np.stack(result_image))

    return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.

def to_padded_chars(integer, max_len=3, pad_right=False):
    """
    Returns a string of len()=max_len, containing the integer padded with ' ' on either right or left side
    """
    length = len(str(integer))
    padding = (max_len - length) * ' '
    if pad_right:
        return str(integer) + padding
    else:
        return padding + str(integer)

# Illustrate the generated query/answer pairs

# Setup
unique_characters = '0123456789+- '         # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)
highest_integer = 99                        # Highest value of integers contained in the queries

max_int_length = len(str(highest_integer))  # Maximum number of characters in an integer
max_query_length = max_int_length * 2 + 1   # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])
max_answer_length = 3                       # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')

# Create the data (might take around a minute)
(MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()
X_text, X_img, y_text, y_img = create_data(highest_integer)
print(X_text.shape, X_img.shape, y_text.shape, y_img.shape)

## Display the samples that were created
def display_sample(n):
    labels = ['X_img:', 'y_img:']
    for i, data in enumerate([X_img, y_img]):
        plt.subplot(1,2,i+1)
        # plt.set_figheight(15)
        plt.axis('off')
        plt.title(labels[i])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    print('='*50, f'\nQuery #{n}\n\nX_text: "{X_text[n]}" = y_text: "{y_text[n]}"')
    plt.show()

for _ in range(10):
    display_sample(np.random.randint(0, 10000, 1)[0])

"""## Helper functions

The functions below will help with input/output of the data.
"""

# One-hot encoding/decoding the text queries/answers so that they can be processed using RNNs
# You should use these functions to convert your strings and read out the output of your networks

def encode_labels(labels, max_len=3):
  n = len(labels)
  length = len(labels[0])
  char_map = dict(zip(unique_characters, range(len(unique_characters))))
  one_hot = np.zeros([n, length, len(unique_characters)])
  for i, label in enumerate(labels):
      m = np.zeros([length, len(unique_characters)])
      for j, char in enumerate(label):
          m[j, char_map[char]] = 1
      one_hot[i] = m

  return one_hot


def decode_labels(labels):
    pred = np.argmax(labels, axis=1)
    predicted = ''.join([unique_characters[i] for i in pred])

    return predicted

X_text_onehot = encode_labels(X_text)
y_text_onehot = encode_labels(y_text)

print(X_text_onehot.shape, y_text_onehot.shape)

for i in range(4):

  # print(f"Encoded X_test[{i}]: \n", X_text_onehot[i])
  # print("Decoded: ",decode_labels(X_text_onehot[i]))
  print(f"Encoded y_test[{i}]: \n", y_text_onehot[i])
  print("Decoded: ",decode_labels(y_text_onehot[i]))

"""---
---

## I. Text-to-text RNN model

The following code showcases how Recurrent Neural Networks (RNNs) are built using Keras. Several new layers are going to be used:

1. LSTM (Long short-term memory)
2. TimeDistributed
3. RepeatVector

The code cell below explains each of these new components.

<img src="https://i.ibb.co/NY7FFTc/Screenshot-2023-11-10-at-09-27-25.png" alt="Screenshot-2023-11-10-at-09-27-25" border="0" width="500"></a>

#### Build model
"""

def build_text2text_model(summary: bool = False, max_answer_length: int = 3,
                          num_encode_layers: int = 1, num_decode_layers: int = 1,
                          metrics=['accuracy', 'mse']):

    # We start by initializing a sequential model
    text2text = tf.keras.Sequential()

    # "Encode" the input sequence using an RNN, producing an output of size 256.
    # In this case the size of our input vectors is [5, 13] as we have queries of length 5 and 13 unique characters. Each of these 5 elements in the query will be fed to the network one by one,
    # as shown in the image above (except with 5 elements).

    # Hint: In other applications, where your input sequences have a variable length (e.g. sentences), you would use input_shape=(None, unique_characters).

    if num_encode_layers == 1:
        text2text.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=False))
    else:
        text2text.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=True))
        for _ in range(num_encode_layers - 2):
            text2text.add(LSTM(256,return_sequences=True))
        text2text.add(LSTM(256, return_sequences=False))

    # As the decoder RNN's input, repeatedly provide with the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the output (e.g. '  1-99' = '-98')
    # when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.
    text2text.add(RepeatVector(max_answer_length))

    # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim). This is necessary as TimeDistributed in the below expects
    # the first dimension to be the timesteps.
    for i in range(num_decode_layers):
        text2text.add(LSTM(256, return_sequences=True))

    # Apply a dense layer to the every temporal slice of an input. For each of step of the output sequence, decide which character should be chosen.
    text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))

    # Next we compile the model using categorical crossentropy as our loss function.
    text2text.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)

    if summary:
        text2text.summary()

    return text2text

model = build_text2text_model(summary=True)

"""#### Hyperparameter tuning"""

## Your code (look at the assignment description for your tasks for text-to-text model):

def split_test(splits = np.linspace(0.1, 0.9, 9),
               data_slice=None,
               test_hyperparams: float = False,
               eval: float = False, batch_sizes = [32, 64, 128, 256],
               epochs = [20, 30, 40]):

  if test_hyperparams:
    print("Starting test for hyperparameters and splits.")
    results = []
    for i in splits:
      # Create training and test sets
      if data_slice == None:
        X_train, X_test, y_train, y_test = train_test_split(X_text_onehot, y_text_onehot, train_size=i)
      else:
        X_train, X_test, y_train, y_test = train_test_split(X_text_onehot[:data_slice], y_text_onehot[:data_slice], train_size=i)

      # Go over hyperparameters
      for batch in batch_sizes:
        for epoch_num in epochs:
          print(f"Now testing split {i = }, batch size {batch}, epoch num {epoch_num}")
          # Initialize model
          T2T = build_text2text_model()
          # Fit model
          history = T2T.fit(X_train, y_train, batch_size=batch, validation_split=1-i, epochs=epoch_num, verbose=0, shuffle=True)

          # Get the accuracy and validation accuracy
          Train_acc = history.history['accuracy']
          Test_acc = history.history['val_accuracy']

          # Append train test acc and corresponding batch size and number of epochs
          results.append([Train_acc, Test_acc, {'batch': batch,
                                                'Epoch num': epoch_num,
                                                'split size': i}])

          # Evaluate model
          if eval:
            T2T.evaluate(X_test, y_test)

    return results

  else:
    print("Starting test for splits with default hyperparameters.")
    results = []
    for i in splits:
      print(f"Now testing split {i = }")
      # Create training and test sets
      if data_slice == None:
        X_train, X_test, y_train, y_test = train_test_split(X_text_onehot, y_text_onehot, train_size=i)
      else:
        X_train, X_test, y_train, y_test = train_test_split(X_text_onehot[:data_slice], y_text_onehot[:data_slice], train_size=i)

      # Initialize model
      T2T = build_text2text_model()
      # Fit model
      history = T2T.fit(X_train, y_train, batch_size=256, validation_split=1-i, epochs=20, verbose=0, shuffle=True)

      # Get the accuracy and validation accuracy
      Train_acc = history.history['accuracy']
      Test_acc = history.history['val_accuracy']
      results.append([Train_acc, Test_acc])

      # Evaluate model
      if eval:
        T2T.evaluate(X_test, y_test)

    return results

"""#### First run of hyperparameter tuning"""

result_default = split_test(splits = np.linspace(0.1, 0.9, 9),
                            data_slice=None, test_hyperparams=False,
                            batch_sizes = [32, 64, 128, 256],
                            epochs = [20, 30, 40])

"""#### Make a plot of accuracy for training and testing for the default hyperparameters"""

def multi_subplot(images, n=3, splits = np.linspace(0.1, 0.9, 9)):
    plt.figure(figsize=(6, 6))
    for i in range(n**2):
        plt.subplot(n, n, i+1)
        plt.subplots_adjust(left=0.1, right=1.5, bottom=0.1, top=0.9, wspace=0.4, hspace=0.8)
        plt.title(f"Training and testing split {round(splits[i], 2)}", fontsize=10)
        plt.xlabel("Epoch")
        plt.ylabel("Accuracy")
        # Plot training and testing accuracy
        plt.plot(np.linspace(1, len(images[i][0]), len(images[i][0])), images[i][0], label='Training', color='blue')
        plt.plot(np.linspace(1, len(images[i][0]), len(images[i][0])), images[i][1], label='Testing', color='red')
        plt.grid()

    plt.legend(loc=(1.2, 4))


    plt.show()

multi_subplot(result_default, n=3)

"""#### Find the best combination of batch size, epochs and split size

Now find the best set, run with varying batch size and number of epochs. Also use the result from above, a split size that is too small will not give good accuracy. We should start with splits of 0.25, moving up in steps of 0.25, i.e. 0.25, 0.5, 0.75 and finally use 0.9.

After this, find the highest accuracies (top 9) of the simulated combinations of hyperparameters for the text2text model, and plot the curves in similar fashion as done directly in the code block above.
"""

result_hyperparam = split_test(splits = [0.25, 0.5, 0.75, 0.9],
                               data_slice=None, test_hyperparams=True,
                               batch_sizes = [32, 64, 128, 256],
                                epochs = [20, 30, 40])

# Initialize a list to store the top 5 elements
top_5_count = [0]
top_5_values = [0]
top_5_acc_train = [0]
# Iterate through the list
for index, sublist in enumerate(result_hyperparam):
    # Extract the first subsublist
    first_subsublist = sublist[0]

    # Calculate the last value of training accuracy
    current_value = first_subsublist[-1]

    # Check if the current value is greater than the smallest value in the top 9 list
    if current_value > min(top_5_acc_train):

      # if top 9 is full, remove the lowest score
      if len(top_5_acc_train) == 5:
          # Find index of lowest training acc
          min_index = top_5_acc_train.index(min(top_5_acc_train))

          # Remove item from all lists
          top_5_acc_train.remove(min(top_5_acc_train))
          top_5_count.remove(top_5_count[min_index])
          top_5_values.remove(top_5_values[min_index])

      # If so, add the current element to the top 9 list
      top_5_acc_train.append(current_value)
      top_5_count.append(index)
      top_5_values.append(sublist)


# Sort the top 9 list based on the values in descending order
top_5_index = sorted(top_5_count, reverse=True)
top_5_index

# Sort the list of sublists based on the values of their first elements in descending order
sorted_top_5_values = sorted(top_5_values, key=lambda x: x[0], reverse=True)

for i in sorted_top_5_values:
  sublist = i[0]
  print(sublist[-1])

"""Best model is"""

sorted_top_5_values[0][-1]

"""#### Check for the highest performance model which instances are labelled wrong.


1. First we have to re-run using the hyperparams to create the network.
2.   We then save the weights, followed by creating a prediction on all instances
3. Lastly, we check the which instances are labbeled incorrectly. Check for example if it is a sign difference, or how large the differences are.


"""

X_train, X_test, y_train, y_test = train_test_split(X_text_onehot, y_text_onehot, train_size=0.9)
# Initialize model
T2T = build_text2text_model()
# Fit model
history = T2T.fit(X_train, y_train, batch_size=32, validation_split=1-0.9, epochs=20, verbose=1, shuffle=True)
# Save weights
T2T.save_weights('/content/drive/MyDrive/IDL/weights_1_2_T2T.keras')

"""Save evolution of accuracy on training and test set"""

train_acc = history.history['accuracy']
test_acc = history.history['val_accuracy']

my_array = np.array(train_acc)
filename = 'train_acc_1_2.npy'
np.save('/content/drive/MyDrive/IDL'+filename, my_array)

my_array = np.array(test_acc)
filename = 'test_acc_1_2.npy'
np.save('/content/drive/MyDrive/IDL'+filename, my_array)

"""Plot evolution over epochs"""

from google.colab import drive
drive.mount('/content/drive')

train_acc = np.load('/content/drive/MyDrive/IDLtrain_acc_1_2.npy')
test_acc = np.load('/content/drive/MyDrive/IDLtest_acc_1_2.npy')

plt.plot(np.linspace(1, len(train_acc), len(train_acc)), train_acc, color='blue', label='Training')
plt.plot(np.linspace(1, len(test_acc), len(test_acc)), test_acc, color='red', label='Testing')
plt.xlabel("Epochs", fontsize=14)
plt.ylabel("Accuracy", fontsize=14)
plt.grid()
plt.xticks(np.arange(1, len(train_acc)+1, 1))
plt.legend()
plt.show()

"""Predictions"""

T2T.load_weights('/content/drive/MyDrive/IDL/weights_1_2_T2T.keras')
y_pred = T2T.predict(X_text_onehot)

"""Example of extracting the prediction"""

def decode_all(predictions):
  decoded_predicitons = np.array([])
  for prediction in predictions:
    decoded_predicitons = np.append(decoded_predicitons, decode_labels(prediction))
  return decoded_predicitons

decoded_predictions = decode_all(y_pred)

decoded_predictions

y_text

"""Check the number of correctly classified instances"""

def check_classification(y_pred, y_true):
  correct = 0
  incorrect = 0
  incorrect_dict = {'y_pred': [],
                    'y_true': []}
  incorrect_indices = []

  for index, value in enumerate(y_true):
    if value == y_pred[index]:
      correct +=1
    else:
      incorrect +=1
      incorrect_indices.append(index)
      incorrect_dict['y_pred'].append(y_pred[index])
      incorrect_dict['y_true'].append(value)


  return correct, incorrect, incorrect_indices, incorrect_dict

correct_num, incorrect_num, incorrect_indices, diction = check_classification(decoded_predictions, y_text)

"""Visualize the incorrectly labbeled instances. In order to do so, we need to convert our strings to integers. Note that due to white spacing we must first subtract any white spacing, before converting to integers. Furthermore, we should note exceptions such as '- ' which is basically just a black, we should completely remove these, but do count them up. These are of course completely wrong as no number is present."""

def process_strings(input_list):
    cleaned_list = []
    invalid_count = 0

    for item in input_list:
        # Remove white spaces and leading/trailing dashes
        cleaned_item = item.replace(" ", "")
        # Replace double white spaces with a single space
        cleaned_item = ' '.join(cleaned_item.split())

        try:
            # Convert the cleaned item to an integer
            cleaned_item_int = int(cleaned_item)
            cleaned_list.append(cleaned_item_int)
        except ValueError:
            # Handle the case where conversion to integer is not possible
            # If such a case arises, append a value of 999
            cleaned_list.append(999)
            invalid_count += 1

    return cleaned_list, invalid_count

# Example usage:
input_strings = [" 123 ", "45", "- 67", "89- ", "  -  10 ", "abc", "12  34"]
cleaned_numbers, invalid_count = process_strings(input_strings)

print("Cleaned Numbers:", cleaned_numbers)
print("Invalid Count:", invalid_count)

# Apply to wrong instances
cleaned_wrong_classified, invalid_count_wrong_classified = process_strings(decoded_predictions[incorrect_indices])
cleaned_true, invalid_true = process_strings(y_text[incorrect_indices])

# Check for invalid cases
print(invalid_count_wrong_classified, invalid_true)

"""Visualize the wrongly labelled instances"""

plt.figure(figsize=(6, 6))
artists = {}
# Plot instances that were wrongly labeled
for count, value in enumerate(cleaned_wrong_classified):
    artist = plt.scatter(count, value, color='red', marker='x', s=25)
    artists['Wrongly predicted values'] = artist

# Plot true values of the wrongly classified instances
for count, value in enumerate(cleaned_true):
    all_instances_artist = plt.scatter(count, value, color='blue', marker='o', s=25, alpha=0.4)
    artists['True values'] = all_instances_artist

# Customize the plot
plt.xlabel('Instance index')
plt.ylabel('Instance value')
plt.grid()
# Create a legend with unique labels
plt.legend(artists.values(), artists.keys())
plt.show()

# Create the same figure but only plot values below 200
cleaned_wrong_classified = np.array(cleaned_wrong_classified)
cleaned_true = np.array(cleaned_true)
mask = cleaned_wrong_classified < 200

# Plot
plt.figure(figsize=(6, 6))
artists = {}
# Plot instances that were wrongly labeled
for count, value in enumerate(cleaned_wrong_classified[mask]):
    artist = plt.scatter(count, value, color='red', marker='x', s=25)
    artists['Wrongly predicted values'] = artist

# Plot true values of the wrongly classified instances
for count, value in enumerate(cleaned_true[mask]):
    all_instances_artist = plt.scatter(count, value, color='blue', marker='o', s=25, alpha=0.4)
    artists['True values'] = all_instances_artist

# Customize the plot
plt.xlabel('Instance index')
plt.ylabel('Instance value')
plt.grid()
plt.legend(artists.values(), artists.keys())
plt.show()

"""Make a sub plot that plots in batches of 250 to obtain better visability."""

# Set the batch size
batch_size = 250

# Get the total number of instances
total_instances = len(cleaned_wrong_classified[mask])

# Calculate the number of subplots needed
num_subplots = int(np.ceil(total_instances / batch_size))

# Calculate the number of rows and columns for the subplot grid
num_rows = int(np.sqrt(num_subplots))
num_cols = int(np.ceil(num_subplots / num_rows))

# Create a subplot grid
fig, axs = plt.subplots(num_rows, num_cols, figsize=(24, 12))

# Flatten the axs array if it's a multi-dimensional array
axs = axs.flatten()

# Plot instances in batches of 250
for i in range(num_subplots):
    start_index = i * batch_size
    end_index = min((i + 1) * batch_size, total_instances)

    # Use the current subplot
    ax = axs[i]

    # Plot instances that were wrongly labeled
    ax.scatter(range(start_index, end_index), cleaned_wrong_classified[mask][start_index:end_index],
               color='red', marker='x', label='Wrongly predicted values', s=25)

    # Plot true values of the wrongly classified instances
    ax.scatter(range(start_index, end_index), cleaned_true[mask][start_index:end_index],
               color='blue', marker='o', label='True values', s=25, alpha=0.4)

    # Customize the subplot
    ax.set_xlabel('Instance index')
    ax.set_ylabel('Instance value')
    ax.set_title(f'Subplot {i+1}')
    ax.grid()

    # Create a legend with unique labels
    ax.legend()

# Adjust layout to prevent clipping of titles
plt.tight_layout()

# Display the grid of subplots
plt.show()

"""Make seperate plots for positive and negative true labels"""

# Positive - using the mask defined in the function
def make_subplot_figure(mask= cleaned_true > 0 , batch_size=250):
  total_instances = len(cleaned_wrong_classified[mask])
  num_subplots = int(np.ceil(total_instances / batch_size))
  num_rows = int(np.sqrt(num_subplots))
  num_cols = int(np.ceil(num_subplots / num_rows))
  fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))
  axs = axs.flatten()
  for i in range(num_subplots):
      start_index = i * batch_size
      end_index = min((i + 1) * batch_size, total_instances)
      ax = axs[i]
      ax.scatter(range(start_index, end_index), cleaned_wrong_classified[mask][start_index:end_index],
                color='red', marker='x', label='Wrongly predicted values', s=25)
      ax.scatter(range(start_index, end_index), cleaned_true[mask][start_index:end_index],
                color='blue', marker='o', label='True values', s=25, alpha=0.4)
      ax.set_xlabel('Instance index')
      ax.set_ylabel('Instance value')
      ax.set_title(f'Subplot {i+1}')
      ax.grid()

      ax.legend()

  plt.tight_layout()
  plt.show()

make_subplot_figure()

# Negative
make_subplot_figure(mask = cleaned_true < 0)

"""### Part 1.5: checking for multiple decoding and encoding layers for Text-to-text model"""

def test_num_decode_encode(num_of_decodes = [1,2,3,4,5],
                           num_of_encodes = [1,2,3,4,5]):
  # Create datasets
  X_train, X_test, y_train, y_test = train_test_split(X_text_onehot, y_text_onehot, train_size=0.9)
  # Iterate over encoder en decoder numbers
  for i in num_of_decodes:
    for j in num_of_encodes:
      with strategy.scope():
        print(f"Testing {i} decode, {j} encode layers")
        model = build_text2text_model(summary=False, num_encode_layers=j, num_decode_layers=i, metrics=['accuracy', 'mse'])
        model.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=30, verbose=0)
        print("\nResult - test set:")
        model.evaluate(X_test,y_test)
        print("\nResult - training set:")
        model.evaluate(X_train,y_train)


test_num_decode_encode(num_of_decodes = [1],
                       num_of_encodes = [1,2,3,4,5])

test_num_decode_encode(num_of_decodes = [1,2,3,4,5],
                       num_of_encodes = [1])

"""Figures of performance"""

# Results for varying encoders. # Column 0: loss, Column 1: accuracy, Column 2: MSE
T2T_varying_encoders_testset_add_sub = np.array([[0.2326, 0.9185, 0.0096],
                                          [0.0635, 0.9790, 0.0025],
                                          [0.3750, 0.8818, 0.0143],
                                          [0.5224, 0.7713, 0.0203],
                                          [0.4866, 0.7912, 0.0189]
                                          ])

T2T_varying_encoders_trainset_add_sub = np.array([[0.2179, 0.9234, 0.0090],
                                          [0.0630, 0.9799, 0.0025],
                                          [0.3641, 0.8817, 0.0142],
                                          [0.5159, 0.7799, 0.0200],
                                          [0.4780, 0.8055, 0.0185]
                                          ])


# Results for varying decoders. # Column 0: loss, Column 1: accuracy, Column 2: MSE
T2T_varying_decoders_testset_add_sub = np.array([[0.0855, 0.9723, 0.0034],
                                         [0.0326, 0.9903, 0.0012],
                                         [0.3889, 0.8510, 0.0159],
                                         [0.3276, 0.8668, 0.0133],
                                         [0.2119, 0.9180, 0.0084],
                                         ])

T2T_varying_decoders_trainset_add_sub = np.array([[0.0708, 0.9788, 0.0027],
                                          [0.0218, 0.9950, 7.1913e-04],
                                          [0.3744, 0.8577, 0.0153],
                                          [0.3006, 0.8785, 0.0124],
                                          [0.1989, 0.9210, 0.0080]
                                          ])

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_testset_add_sub[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_trainset_add_sub[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of encoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_testset_add_sub[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_trainset_add_sub[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of encoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_testset_add_sub[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_trainset_add_sub[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of decoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_testset_add_sub[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_trainset_add_sub[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of decoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

"""---
---

## II. Image to text RNN Model

Hint: There are two ways of building the encoder for such a model - again by using the regular LSTM cells (with flattened images as vectors) or recurrect convolutional layers [ConvLSTM2D](https://keras.io/api/layers/recurrent_layers/conv_lstm2d/).

The goal here is to use **X_img** as inputs and **y_text** as outputs.

### With ConvLSTM2D:
"""

def build_img2text_model_conv(show_summary: bool = False,
                              metrics = ["accuracy"],
                              num_encode_layers: int = 1,
                              num_decode_layers: int = 1,
                              learning_rate: float=0.001,
                              max_answer_length: int=3):
    # Encode: looks at sequence of 5 images
    img2text = tf.keras.Sequential()

    if num_encode_layers == 1:
        img2text.add(ConvLSTM2D(filters=400,kernel_size=(3,3),padding='same',
                                data_format='channels_last',return_sequences=True,input_shape=(5,28,28,1)))
        img2text.add(ConvLSTM2D(filters=1,kernel_size=(3,3),padding='same',
                                data_format='channels_last',return_sequences=False))

    else:
        img2text.add(ConvLSTM2D(filters=400,kernel_size=(3,3),padding='same',
                                data_format='channels_last',return_sequences=True,input_shape=(5,28,28,1)))

        for _ in range(num_encode_layers - 2):
            img2text.add(ConvLSTM2D(filters=400,kernel_size=(3,3),padding='same',
                                    data_format='channels_last',return_sequences=True))

        img2text.add(ConvLSTM2D(filters=1,kernel_size=(3,3),padding='same',
                                data_format='channels_last', return_sequences=False))

    # Reshape and flatten to get single output, i.e. we need to now go the decoder which outputs text
    img2text.add(Reshape((28,28)))
    img2text.add(Flatten())
    img2text.add(RepeatVector(max_answer_length))

    for i in range(num_decode_layers):
        img2text.add(LSTM(400, return_sequences=True))

    # Apply a dense layer to the every temporal slice of an input. For each of step of the output sequence, decide which character should be chosen.
    img2text.add(TimeDistributed(Dense(400, activation='relu')))
    img2text.add(TimeDistributed(Dense(200, activation='relu')))
    img2text.add(TimeDistributed(Dense(100, activation='relu')))
    img2text.add(TimeDistributed(Dense(50, activation='relu')))

    img2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))

    # Next we compile the model using categorical crossentropy as our loss function.
    opt = keras.optimizers.Adam(learning_rate=learning_rate)
    img2text.compile(loss='categorical_crossentropy', optimizer='adam',
                     metrics=metrics, steps_per_execution=25)
    if show_summary:
        img2text.summary()

    return img2text

convmodel = build_img2text_model_conv(show_summary=True, num_encode_layers=1, num_decode_layers=1)

# Train, fit and plot the ConvLSTM2D utilizing image-to-text model. Using the hyperparameters found from the T2T model.

split = 0.9
X_train, X_test, y_train, y_test = train_test_split(X_img, y_text_onehot, train_size=split)
with strategy.scope():
  convmodel = build_img2text_model_conv(show_summary=False, num_decode_layers=1, num_encode_layers=1)
  history = convmodel.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=15)
  Train_acc = history.history['accuracy']
  Test_acc = history.history['val_accuracy']
  convmodel.evaluate(X_test,y_test)

plt.plot(np.arange(1, 15+1), Train_acc, label='Training', color='blue')
plt.plot(np.arange(1, 15+1), Test_acc, label='Testing', color='red')
plt.grid()
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend()
plt.show()

"""### Without ConvLSTM2D:"""

def build_img2text_model(show_summary: bool = False, metrics = ["accuracy"],
                         num_encode_layers: int = 1,num_decode_layers:int = 1,
                         learning_rate: float=0.001, max_answer_length: int=3):
    # We start by initializing a sequential model
    img2text = tf.keras.Sequential()

    # "Encode" the input sequence using an RNN, producing an output of size 256.
    # In this case the size of our input vectors is [5, 28, 28] as we have queries of length 5 and 28x28 images. Each of these 5 elements in the query will be fed to the network one by one.
    # We reshape the input vector to be [5, 28*28]
    img2text.add(Reshape((5, 28*28), input_shape=(5, 28, 28)))
    if num_encode_layers == 1:
        img2text.add(LSTM(400, input_shape=(None, len(unique_characters)),return_sequences=False))
    else:
        img2text.add(LSTM(400, input_shape=(None, len(unique_characters)),return_sequences=True))
        for _ in range(num_encode_layers - 2):
            img2text.add(LSTM(400,return_sequences=True))
        img2text.add(LSTM(400, return_sequences=False))

    # As the decoder RNN's input, repeatedly provide with the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the output (e.g. '  1-99' = '-98')
    # when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.
    img2text.add(RepeatVector(max_answer_length))

    # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim). This is necessary as TimeDistributed in the below expects
    # the first dimension to be the timesteps.
    for i in range(num_decode_layers):
        img2text.add(LSTM(400, return_sequences=True))

    # Apply a dense layer to the every temporal slice of an input. For each of step of the output sequence, decide which character should be chosen.
    img2text.add(TimeDistributed(Dense(400, activation='relu')))
    img2text.add(TimeDistributed(Dense(200, activation='relu')))
    img2text.add(TimeDistributed(Dense(100, activation='relu')))
    img2text.add(TimeDistributed(Dense(50, activation='relu')))

    # Output
    img2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))

    # Next we compile the model using categorical crossentropy as our loss function.
    opt = keras.optimizers.Adam(learning_rate=learning_rate)
    img2text.compile(loss='categorical_crossentropy', optimizer=opt,
                     metrics=metrics, steps_per_execution=25)
    if show_summary:
        img2text.summary()

    return img2text

build_img2text_model(show_summary=True, num_encode_layers=3, num_decode_layers=1)

# Train, evalutate and plot evolution of model performance using LSTM layers instead of ConvLSTM2D.
split = 0.9
X_train, X_test, y_train, y_test = train_test_split(X_img, y_text_onehot, train_size=split)

with strategy.scope():
  model = build_img2text_model(show_summary=False, num_encode_layers=1, num_decode_layers=1, learning_rate=0.001)
  history = model.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=50)
  Train_acc = history.history['accuracy']
  Test_acc = history.history['val_accuracy']
  print("Result:")
  model.evaluate(X_test,y_test)

plt.plot(np.arange(1, 50+1), Train_acc, label='Training', color='blue')
plt.plot(np.arange(1, 50+1), Test_acc, label='Testing', color='red')
plt.grid()
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend()
plt.show()

"""#### The code part for 1.5, testing multiple combinations of decode and encode for performance."""

def test_num_decode_encode(num_of_decodes = [1,2,3,4,5],
                           num_of_encodes = [1,2,3,4,5]):
  split = 0.9
  X_train, X_test, y_train, y_test = train_test_split(X_img, y_text_onehot, train_size=split)
  for i in num_of_decodes:
    for j in num_of_encodes:
      with strategy.scope():
        print(f"Testing {i} decode, {j} encode layers")
        model = build_img2text_model(show_summary=False, num_encode_layers=j, num_decode_layers=i, metrics=['accuracy', 'mse'])
        model.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=30, verbose=0)
        print("\nResult - test set:")
        model.evaluate(X_test,y_test)
        print("\nResult - training set:")
        model.evaluate(X_train,y_train)


test_num_decode_encode(num_of_decodes = [1],
                       num_of_encodes = [1,2,3,4,5])

test_num_decode_encode(num_of_decodes = [1,2,3,4,5],
                       num_of_encodes = [1])

"""Construct figures"""

# Results for varying encoders. # Column 0: loss, Column 1: accuracy, Column 2: MSE
I2T_varying_encoders_testset_add_sub = np.array([[1.5067, 0.6753, 0.0391],
                                                 [0.6674, 0.8588, 0.0178],
                                                 [0.5405, 0.8875, 0.0141],
                                                 [1.1329, 0.6225, 0.0342],
                                                 [2.0204, 0.3353, 0.0612]
                                                 ])

I2T_varying_encoders_trainset_add_sub = np.array([[0.3027, 0.9118, 0.0103],
                                                  [0.1485, 0.9622, 0.0047],
                                                  [0.1441, 0.9625, 0.0046],
                                                  [0.8237, 0.6961, 0.0254],
                                                  [2.0362, 0.3280, 0.0617]
                                                  ])


# Results for varying decoders. # Column 0: loss, Column 1: accuracy, Column 2: MSE
I2T_varying_decoders_testset_add_sub = np.array([[1.1451, 0.7652, 0.0299],
                                                 [2.0181, 0.5732, 0.0441],
                                                 [1.8209, 0.5592, 0.0440],
                                                 [1.5337, 0.5698, 0.0419],
                                                 [1.5153, 0.5513, 0.0429]

                                         ])

I2T_varying_decoders_trainset_add_sub = np.array([[0.1855, 0.9534, 0.0058],
                                                  [0.6344, 0.7732, 0.0212],
                                                  [0.7541, 0.7224, 0.0243],
                                                  [0.8095, 0.7007, 0.0254],
                                                  [0.8947, 0.6751, 0.0271]
                                          ])

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), I2T_varying_encoders_testset_add_sub[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), I2T_varying_encoders_trainset_add_sub[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of encoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), I2T_varying_encoders_testset_add_sub[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), I2T_varying_encoders_trainset_add_sub[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of encoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), I2T_varying_decoders_testset_add_sub[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), I2T_varying_decoders_trainset_add_sub[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of decoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), I2T_varying_decoders_testset_add_sub[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), I2T_varying_decoders_trainset_add_sub[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of decoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

"""---
---

## III. Text to image RNN Model

Hint: to make this model work really well you could use deconvolutional layers in your decoder (you might need to look up ***Conv2DTranspose*** layer). However, regular vector-based decoder will work as well.

The goal here is to use **X_text** as inputs and **y_img** as outputs.
"""

def build_text2img_model(loss_func: str = 'binary_crossentropy',
                         arch: int = 1,
                         activation: str = 'sigmoid',
                        #  latent_dim: int = 256,
                         show_summary: bool = False, metrics = ["accuracy"],
                         num_encode_layers: int = 1,
                         num_decode_layers: int = 1):

    # We start by initializing a sequential model
    text2img = tf.keras.Sequential()

    if arch == 1:

        # "Encode" the input sequence using an RNN, producing an output of size 256.
        # In this case the size of our input vectors is [5, 13] as we have queries of length 5 and 13 unique characters. Each of these 5 elements in the query will be fed to the network one by one,
        # as shown in the image above (except with 5 elements).
        # Hint: In other applications, where your input sequences have a variable length (e.g. sentences), you would use input_shape=(None, unique_characters).
        if num_encode_layers == 1:
            text2img.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=False))
        else:
            text2img.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=True))
            for _ in range(num_encode_layers - 2):
                text2img.add(LSTM(256,return_sequences=True))
            text2img.add(LSTM(256, return_sequences=False))

        # As the decoder RNN's input, repeatedly provide Part 1: Addition and subtractionith the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the output (e.g. '  1-99' = '-98')
        # when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.
        text2img.add(RepeatVector(max_answer_length))

        # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim).
        # This is necessary as TimeDistributed in the below expects the first dimension to be the timesteps.
        for _ in range(num_decode_layers):
            text2img.add(LSTM(256, return_sequences=True))

        #Reshape the input, upscale to 32x32 and then downscale to 28x28 for the original image size.
        text2img.add(TimeDistributed(Reshape((16,16,1))))
        text2img.add(TimeDistributed(Conv2DTranspose(512,kernel_size=(2,2),strides=(2,2),padding='same',data_format='channels_last')))
        text2img.add(TimeDistributed(Dropout(0.2)))
        text2img.add(TimeDistributed(Conv2D(filters=64,kernel_size=(5,5),data_format='channels_last'))) #changes dimensions back to 28x28x1
        text2img.add(TimeDistributed(Dropout(0.2)))
        text2img.add(TimeDistributed(Conv2D(filters=1,kernel_size=(1,1),padding='same',data_format='channels_last', activation='sigmoid'))) #changes dimensions back to 28x28x1
        text2img.add(TimeDistributed(Dropout(0.2)))
        text2img.add(TimeDistributed(Reshape((28,28))))

    elif arch == 2:

        # "Encode" the input sequence using an RNN, producing an output of size 256.
        # In this case the size of our input vectors is [5, 13] as we have queries of length 5 and 13 unique characters. Each of these 5 elements in the query will be fed to the network one by one,
        # as shown in the image above (except with 5 elements).
        # Hint: In other applications, where your input sequences have a variable length (e.g. sentences), you would use input_shape=(None, unique_characters).
        if num_encode_layers == 1:
            text2img.add(LSTM(49, input_shape=(None, len(unique_characters)),return_sequences=False))
        else:
            text2img.add(LSTM(49, input_shape=(None, len(unique_characters)),return_sequences=True))
            for _ in range(num_encode_layers - 2):
                text2img.add(LSTM(49,return_sequences=True))
            text2img.add(LSTM(49, input_shape=(None, len(unique_characters)),return_sequences=False))
        # As the decoder RNN's input, repeatedly provide with the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the output (e.g. '  1-99' = '-98')
        # when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.
        text2img.add(RepeatVector(max_answer_length))

        # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim).
        # This is necessary as TimeDistributed in the below expects the first dimension to be the timesteps.
        for _ in range(num_decode_layers):
            text2img.add(LSTM(49, return_sequences=True))

        #Reshape the input, upscale to 32x32 and then downscale to 28x28 for the original image size.
        text2img.add(TimeDistributed(Reshape((7,7,1))))
        # changes dimensions to 7x7(32), filter count in parentheses
        text2img.add(TimeDistributed(Conv2DTranspose(32,kernel_size=(1,1),padding='same',data_format='channels_last'))) \
        #-> 14x14(32)
        text2img.add(TimeDistributed(Conv2DTranspose(32,kernel_size=(2,2),strides=(2,2),padding='valid',data_format='channels_last')))
        #-> 28x28(32)
        text2img.add(TimeDistributed(Conv2DTranspose(64,kernel_size=(2,2),strides=(2,2),padding='valid',data_format='channels_last')))
        #-> 28x28(1)
        text2img.add(TimeDistributed(Conv2D(filters=1,kernel_size=(1,1),data_format='channels_last',padding='same', activation='sigmoid')))
        text2img.add(TimeDistributed(Reshape((28,28))))

    elif arch == 3:

        if num_encode_layers == 1:
            text2img.add(LSTM(9*9*4, input_shape=(None, len(unique_characters)),return_sequences=False))
        else:
            text2img.add(LSTM(9*9*4, input_shape=(None, len(unique_characters)),return_sequences=True))
            for _ in range(num_encode_layers - 2):
                text2img.add(LSTM(9*9*4,return_sequences=True))
            text2img.add(LSTM(9*9*4, input_shape=(None, len(unique_characters)),return_sequences=False))

        for _ in range(num_decode_layers):
            text2img.add(LSTM(9*9*4, return_sequences=True))

        text2img.add(RepeatVector(max_answer_length))

        #Reshape the input, upscale to 32x32 and then downscale to 28x28 for the original image size.
        text2img.add(TimeDistributed(Reshape((9,9,4))))
        text2img.add(TimeDistributed(Conv2D(filters=32, kernel_size=3))) # changes dimensions to (7, 7, 32)
        text2img.add(TimeDistributed(Conv2DTranspose(32, 2, 2))) # changes dimensions to (14, 14, 32)
        text2img.add(TimeDistributed(Conv2DTranspose(64, 2, 2))) # changes dimensions to (28, 28, 64)
        text2img.add(TimeDistributed(Conv2D(filters=1, kernel_size=(5,5), padding='same', activation='sigmoid'))) #changes dimensions back to 28x28x1
        text2img.add(TimeDistributed(Reshape((28,28))))

    elif arch == 4:
        if num_encode_layers == 1:
            text2img.add(LSTM(1024, input_shape=(None, len(unique_characters)),return_sequences=False))
        else:
            text2img.add(LSTM(1024, input_shape=(None, len(unique_characters)),return_sequences=True))
            for _ in range(num_encode_layers - 2):
                text2img.add(LSTM(1024,return_sequences=True))
            text2img.add(LSTM(1024,return_sequences=False))

        text2img.add(RepeatVector(28)) #number of pixels in one dimension
        for _ in range(num_decode_layers):
            text2img.add(LSTM(1024, return_sequences=True))

        text2img.add(TimeDistributed(Dense(256)))
        text2img.add(TimeDistributed(Dropout(0.5)))
        text2img.add(TimeDistributed(Dense(28 * 3, activation='sigmoid')))  # Output 3 sets of 28 pixels per time step
        text2img.add(Reshape((3,28, 28)))
    # Next we compile the model using binary crossentropy or mse as our loss function.
    text2img.compile(loss='mean_squared_error', optimizer='adam', metrics=metrics)
    # text2img.compile(loss='binary_crossentropy', optimizer='adam', metrics=metrics)
    if show_summary:
        text2img.summary()

    return text2img

model = build_text2img_model(arch=4,num_encode_layers = 2, num_decode_layers = 1,show_summary=True)

"""Create input and output of T2I model"""

inputs = X_text_onehot
outputs = y_img
state = np.random.randint(1000000)
X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, train_size=float(0.9),random_state=state)
X_train_img, X_test_img, y_train_onehot, y_test_onehot = train_test_split(X_img, y_text_onehot, train_size=float(0.9),random_state=state)

"""Use fit kwargs found from previous tasks, batch size of 32, 30 epochs and 90/10% training/test set splits.

Fit the model and display predictions.
"""

fit_kwargs = {
        'batch_size': 32,
        'validation_split': 0.1,
        'epochs': 30,
        }

metrics = ['accuracy']

train_score = [np.nan]*(len(metrics)+1)
test_score = [np.nan]*(len(metrics)+1)
inputs = X_text_onehot
outputs = y_img

with strategy.scope():
    model = build_text2img_model(arch=4,num_encode_layers = 2, num_decode_layers = 1,show_summary=False)
    model.fit(X_train, y_train, **fit_kwargs, verbose=1)
    pred = model.predict(X_test) # approximation of y_test

"""Display some predictions"""

def display_sample_prediction(n):
    labels = ['y_pred:', 'y_test:']
    for j, data in enumerate([pred, y_test]):
        plt.subplot(1,2,j+1)
        plt.axis('off')
        plt.title(labels[j])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    plt.show()

print(pred.shape)
for i in np.random.randint(0,pred.shape[0],5):
  display_sample_prediction(i)

"""Display predictions and true values to have a better understanding of the model performance."""

def evaluate_text2img(show_summary=False,
                      metrics = ['accuracy']):

    mod = tf.keras.Sequential()
    mod.add(Reshape((3,28*28),input_shape=(3,28,28)))
    mod.add(Dense(364,activation='relu'))
    mod.add(BatchNormalization())
    mod.add(Dropout(0.5))

    mod.add(Dense(52,activation = 'relu'))
    mod.add(BatchNormalization())
    mod.add(Dropout(0.5))

    mod.add(Dense(len(unique_characters),activation='softmax'))

    mod.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)

    if show_summary:
        mod.summary()

    return mod

with strategy.scope():
    mod = evaluate_text2img()
    mod.summary()
    mod.fit(y_train,y_train_onehot,epochs=20,validation_split=0.1,batch_size=32,verbose=1)
    mod.evaluate(y_test,y_test_onehot)

pred_onehot = mod.predict(pred)
for i in range(5):
    pred_text = decode_labels(pred_onehot[i])
    real_text = decode_labels(y_test_onehot[i])
    print(f"Prediction: {pred_text}, real: {real_text}")

accs = []
individual_cases = np.array([0,0,0])
for i in range(len(pred_onehot)):
    pred_text = decode_labels(pred_onehot[i])
    real_text = decode_labels(y_test_onehot[i])
    if i < 3:
        print(f"Prediction: {pred_text}, real: {real_text}")
    acc = 0.
    for char in range(3):
        if pred_text[char] == real_text[char]:
            acc += 1.
            individual_cases[char] += 1
    acc /= 3
    accs.append(acc)

full_acc = np.sum(np.array([decode_labels(x) for x in pred_onehot]) == np.array([decode_labels(y) for y in y_test_onehot]))/pred.shape[0]

print(f"Mean achieved accuracy = {np.mean(accs)} and median {np.median(accs):.4f} and mode {mode(accs)[0]:.4f}")
print(f"Full accuracy (not splitting the three predictions) is {full_acc:.4f}")
print(individual_cases, individual_cases/pred.shape[0])

for i in range(10):
    mask = (MNIST_labels == i)
    ones = MNIST_data[mask]
    average_one = np.mean(ones,axis=0)
    plt.imshow(average_one,cmap='gray')
    plt.axis('off')
    plt.title(f"Average \"{i}\" in MNIST data",fontsize=16)
    plt.tight_layout()
    plt.show()

def T2I_accuracy(y_pred, y_true):
    accuracies = []
    individual_acc = np.array([0,0,0])
    for prediction, truth in zip(y_pred, y_true):
        acc=0
        prediction_text = decode_labels(prediction)
        truth_text = decode_labels(truth)
        for c in range(3):
            if prediction_text[c] == truth_text[c]:
                acc += 1
                individual_acc[c] += 1
        accuracies.append(acc/3)
    for c in range(3):
        individual_acc[c]/=len(y_pred)

    full_acc = np.sum(np.array([decode_labels(x) for x in y_pred]) == np.array([decode_labels(y) for y in y_true]))/y_pred.shape[0]
    return full_acc, accuracies, individual_acc

# Encode/decode analysis
def test_encode_decode(run_mode: str = "encode", max_num: int = 5):
    ids = np.arange(len(X_text_onehot))
    train_ids, test_ids = train_test_split(ids, train_size=float(0.9))

    with strategy.scope():
        print("Initialising evaluation model")
        eval_model = evaluate_text2img()
        eval_model.fit(y_img[train_ids], y_text_onehot[train_ids], batch_size = 32, validation_split=0.1, epochs = 20, verbose=0)
        print("Performance of eval model:")
        score = eval_model.evaluate(y_img[test_ids], y_text_onehot[test_ids], verbose=0)
        print(f"Loss: {score[0]:.3f}")
        print(f"Accuracy: {score[1]:.3f}")
        print()

        if run_mode == "encode":
            n_decode = 1
            # test encoding layers
            for n_encode in range(1, max_num + 1):
                print(f"N_encode: {n_encode}, N_decode: {n_decode}")
                model = build_text2img_model(arch=4, num_encode_layers = n_encode, num_decode_layers = n_decode, show_summary=False)
                model.fit(X_text_onehot[train_ids], y_img[train_ids], batch_size = 32, validation_split=0.1, epochs = 30)
                prediction = model.predict(X_text_onehot[test_ids])
                evaluation = eval_model.predict(prediction)
                full_acc, acc, indiv_acc = T2I_accuracy(evaluation, y_text_onehot[test_ids])
                print(f"Accuracies:")
                print(f"\tFull: {full_acc:.4f}")
                print(f"\tMean: {np.mean(acc):.4f}")
                print(f"\tMode: {mode(acc)[0]:.4f}")
                print(f"\tMedian: {np.median(acc):.4f}")
                print(f"\tIndividual: {indiv_acc}")

        elif run_mode == "decode":
            n_encode = 1
            # test decoding layers
            for n_decode in range(1, max_num + 1):
                print(f"N_encode: {n_encode}, N_decode: {n_decode}")
                model = build_text2img_model(arch=4, num_encode_layers = n_encode, num_decode_layers = n_decode, show_summary=False)
                model.fit(X_text_onehot[train_ids], y_img[train_ids], batch_size = 32, validation_split=0.1, epochs = 30)
                prediction = model.predict(X_text_onehot[test_ids])
                evaluation = eval_model.predict(prediction)
                full_acc, acc, indiv_acc = T2I_accuracy(evaluation, y_text_onehot[test_ids])
                print(f"Accuracies:")
                print(f"\tFull: {full_acc:.4f}")
                print(f"\tMean: {np.mean(acc):.4f}")
                print(f"\tMode: {mode(acc)[0]:.4f}")
                print(f"\tMedian: {np.median(acc):.4f}")
                print(f"\tIndividual: {indiv_acc}")
        else:
            raise Exception(f"Invalid mode `{run_mode}`")

# test_encode_decode('encode')
test_encode_decode('decode')

test_encode_decode('encode',max_)

"""## Initialising evaluation model
Performance of eval model:
- Loss: 0.056
- Accuracy: 0.984

## Accuracies:
### N_encode: 1, N_decode: 1
Accuracies:
- Full: 0.3365
- Mean: 0.7303
- Mode: 0.6667
- Median: 0.6667
- Individual: [0 0 0]

### N_encode: 2, N_decode: 1
- Full: 0.0735
- Mean: 0.5927
- Mode: 0.6667
- Median: 0.6667
- Individual: [0 0 0]

### N_encode: 3, N_decode: 1
- Full: 0.0790
- Mean: 0.6140
- Mode: 0.6667
- Median: 0.6667
- Individual: [0 0 0]

### N_encode: 1, N_decode: 1
- Full: 0.0790
- Mean: 0.7565
- Mode: 0.6667
- Median: 0.6667
- Individual: [0 0 0]

### N_encode: 1, N_decode: 2
Accuracies:
- Full: 0.0630
- Mean: 0.5675
- Mode: 0.6667
- Median: 0.6667
- Individual: [0 0 0]

### N_encode: 1, N_decode: 3
Accuracies:
- Full: 0.0605
- Mean: 0.5558
- Mode: 0.6667
- Median: 0.6667
- Individual: [0 0 0]
"""

accs_enc,ind_accs_enc = [0.4395,0.0735,0.0790],[0.7303,0.5927,0.6140]

accs_dec,ind_accs_dec =  [0.0790,0.0630,0.605],[0.7565,0.5927,0.5558]

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 3+1, 1), accs_enc, color='red', label='Full accuracy')
axes[0].plot(np.arange(1, 3+1, 1), ind_accs_enc, color='blue', label='Mean individual accuracy')
axes[0].set_xticks(np.arange(1, 4, 1))
axes[0].set_xlabel("Number of encoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 3+1, 1), accs_dec, color='red', label='Full accuracy')
axes[1].plot(np.arange(1, 3+1, 1), ind_accs_dec, color='blue', label='Mean individual accuracy')
axes[1].set_xticks(np.arange(1, 4, 1))
axes[1].set_xlabel("Number of decoding layers")
axes[1].set_ylabel("Accuracy")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

"""---
---
---

# Part 2: Multiplication
The cell below will create the multiplication dataset used in this part of the assignment.

#### Generate data
"""

# Illustrate the generated query/answer pairs

unique_characters = '0123456789* '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)
highest_integer = 99                      # Highest value of integers contained in the queries

max_int_length = len(str(highest_integer))# Maximum number of characters in an integer
max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])
max_answer_length = 5    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')

# Create the data (might take around a minute)
(MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()
X_text_mult, X_img_mult, y_text_mult, y_img_mult = create_data(highest_integer, operands=['*'])
print(X_text_mult.shape, X_img_mult.shape, y_text_mult.shape, y_img_mult.shape)


## Display the samples that were created
def display_sample(n):
    labels = ['X_img:', 'y_img:']
    for i, data in enumerate([X_img_mult, y_img_mult]):
        plt.subplot(1,2,i+1)
        # plt.set_figheight(15)
        plt.axis('off')
        plt.title(labels[i])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    print('='*50, f'\nQuery #{n}\n\nX_text: "{X_text_mult[n]}" = y_text: "{y_text_mult[n]}"')
    plt.show()

for _ in range(10):
    display_sample(np.random.randint(0, 10000, 1)[0])

"""Need to one-hot encode the labels:"""

y_text_onehot_mult = encode_labels(y_text_mult)
X_text_onehot_mult = encode_labels(X_text_mult)

"""### Text to text model"""

def build_text2text_mult_model(num_decode_layers: int = 1,num_encode_layers: int = 1,
                               show_summary: bool = False, metrics = ["accuracy"],
                               max_answer_length: int = 5):

    # We start by initializing a sequential model
    text2text = tf.keras.Sequential()

    # "Encode" the input sequence using an RNN, producing an output of size 256.
    # In this case the size of our input vectors is [5, 13] as we have queries of length 5 and 13 unique characters. Each of these 5 elements in the query will be fed to the network one by one,
    # as shown in the image above (except with 5 elements).
    # Hint: In other applications, where your input sequences have a variable length (e.g. sentences), you would use input_shape=(None, unique_characters).
    for i in range(num_encode_layers - 1):
      text2text.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=True))

    text2text.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=False))
    # As the decoder RNN's input, repeatedly provide with the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the output (e.g. '  1-99' = '-98')
    # when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.
    text2text.add(RepeatVector(max_answer_length))

    # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim). This is necessary as TimeDistributed in the below expects
    # the first dimension to be the timesteps.

    for _ in range(num_decode_layers - 1):
      text2text.add(LSTM(256, return_sequences=True))

    text2text.add(LSTM(256, input_shape=(None, len(unique_characters)),return_sequences=True))

    # Apply a dense layer to the every temporal slice of an input. For each of step of the output sequence, decide which character should be chosen.
    text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))

    # Next we compile the model using categorical crossentropy as our loss function.
    text2text.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)
    if show_summary:
        text2text.summary()

    return text2text

build_text2text_mult_model(show_summary=True)

"""### Image to text model
Use the previous model (I2T) from the addition and subtracting exercise.
"""

split = 0.9
X_train, X_test, y_train, y_test = train_test_split(X_img_mult, y_text_onehot_mult, train_size=split)
with strategy.scope():
  model = build_img2text_model(show_summary=False, num_encode_layers=3, num_decode_layers=1, learning_rate=0.001, max_answer_length=5)
  model.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=50)
  print("Result:")
  model.evaluate(X_test,y_test)

"""### Let's do a hyperparameter optimization. Also check for combinations of number of encoders and decoders while keeping one of the two fixed to a value of 1.

#### Hyperparameter testing using image-to-text
"""

def split_test_multiplication(splits = np.linspace(0.1, 0.9, 9),
                              test_hyperparams: float = False,
                              eval: float = False, batch_sizes = [32, 64, 128, 256],
                              epochs = [20, 30, 40]):

  if test_hyperparams:
    print("Starting test for hyperparameters and splits.")
    results = []
    for i in splits:
      # Create training and test sets
      X_train, X_test, y_train, y_test = train_test_split(X_img_mult, y_text_onehot_mult, train_size=i)

      # Go over hyperparameters
      for batch in batch_sizes:
        for epoch_num in epochs:
          print(f"Now testing split {i = }, batch size {batch}, epoch num {epoch_num}")
          # Initialize model
          I2T = build_img2text_model(show_summary=False, num_encode_layers=3, num_decode_layers=1, learning_rate=0.001, max_answer_length=5)
          # Fit model
          history = I2T.fit(X_train, y_train, batch_size=batch, validation_split=1-i, epochs=epoch_num, verbose=0, shuffle=True)

          # Get the accuracy and validation accuracy
          Train_acc = history.history['accuracy']
          Test_acc = history.history['val_accuracy']

          # Append train test acc and corresponding batch size and number of epochs
          results.append([Train_acc, Test_acc, {'batch': batch,
                                                'Epoch num': epoch_num,
                                                'split size': i}])

          # Evaluate model
          if eval:
            I2T.evaluate(X_test, y_test)

    return results

def find_top_5(results):

  # Initialize a list to store the top 5 elements
  top_5_count = [0]
  top_5_values = [0]
  top_5_acc_train = [0]
  # Iterate through the list
  for index, sublist in enumerate(results):
      # Extract the first subsublist
      first_subsublist = sublist[0]

      # Calculate the last value of training accuracy
      current_value = first_subsublist[-1]

      # Check if the current value is greater than the smallest value in the top 9 list
      if current_value > min(top_5_acc_train):
        # if top 9 is full, remove the lowest score
        if len(top_5_acc_train) == 5:
            # Find index of lowest training acc
            min_index = top_5_acc_train.index(min(top_5_acc_train))

            # Remove item from all lists
            top_5_acc_train.remove(min(top_5_acc_train))
            top_5_count.remove(top_5_count[min_index])
            top_5_values.remove(top_5_values[min_index])

        # If so, add the current element to the top 5 list
        top_5_acc_train.append(current_value)
        top_5_count.append(index)
        top_5_values.append(sublist)


  # Sort the top 5 list based on the values in descending order
  top_5_index = sorted(top_5_count, reverse=True)

  # Sort the list of sublists based on the values of their first elements in descending order
  sorted_top_5_values = sorted(top_5_values, key=lambda x: x[0], reverse=True)

  # The best model is
  best = sorted_top_5_values[0][-1]
  return sorted_top_5_values, best

result_hyperparam_multiplication = split_test_multiplication(splits = [0.25, 0.5, 0.75, 0.9],
                                                            test_hyperparams=True,
                                                            batch_sizes = [32, 64, 128],
                                                            epochs = [10, 20, 30])

top5_mult, best_mult = find_top_5(result_hyperparam_multiplication)
print(top5_mult, "\nBest model:", best_mult)

# Create a DataFrame
df = pd.DataFrame(top5_mult, columns=['training accuracy per epoch', 'testing accuracy per epoch', 'hyperparameters'])

# Display the DataFrame
print(df)

"""Best model:

"""

df.iloc[0]

df.iloc[0][0]

plt.plot(np.arange(1, 30+1), df.iloc[0][0], label='Training', color='blue')
plt.plot(np.arange(1, 30+1), df.iloc[0][1], label='Testing', color='red')
plt.grid()
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend()
plt.show()

"""#### Check the combinations of encoder and decoders for image-to-text"""

def test_num_decode_encode_multiplication(num_of_decodes = [1,2,3,4,5],
                                          num_of_encodes = [1,2,3,4,5]):

  X_train, X_test, y_train, y_test = train_test_split(X_img_mult, y_text_onehot_mult, train_size=0.9)

  for i in num_of_decodes:
    for j in num_of_encodes:
      with strategy.scope():
        print(f"Testing {i} decode, {j} encode layers")
        model = build_img2text_model(show_summary=False, max_answer_length=5,
                                     num_encode_layers=j, num_decode_layers=i, metrics=['accuracy','mse'])
        model.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=30, verbose=0)
        print("\nResult - test set:")
        model.evaluate(X_test,y_test)
        print("\nResult - training set")
        model.evaluate(X_train,y_train)

print("Using 1 decoder and varying number of encoders:")
test_num_decode_encode_multiplication(num_of_decodes = [1],
                                      num_of_encodes = [1,2,3,4,5])
print("Using 1 encoder and varying number of decoders:")
test_num_decode_encode_multiplication(num_of_decodes = [1,2,3,4,5],
                                      num_of_encodes = [1])

"""Create data for figure from the printed outputs:"""

# Results for Testing 1 decode and increasing encoding layers (1,2,3,4,5).
# Column 0: loss, Column 1: accuracy, Column 2: MSE
varying_encoders_testset = np.array([[3.1633, 0.5160, 0.0627],
                                     [1.7339, 0.5728, 0.0468],
                                     [1.3111, 0.5892, 0.0404],
                                     [1.2501, 0.5624, 0.0412],
                                     [1.2106, 0.5856, 0.0392]
                                     ])

# Column 0: loss, Column 1: accuracy, Column 2: MSE
varying_encoders_trainset = np.array([[0.5242, 0.8803, 0.0151],
                                      [0.6175, 0.7784, 0.0233],
                                      [0.8533, 0.6658, 0.0307],
                                      [0.8981, 0.6363, 0.0324],
                                      [0.8616, 0.6495, 0.0315]
                                      ])

# Varying decoders, 1 encoder. # Column 0: loss, Column 1: accuracy, Column 2: MSE
varying_decoders_testset = np.array([[3.1341, 0.5104, 0.0625],
                                     [2.2290, 0.5024, 0.0560],
                                     [1.8290, 0.5010, 0.0517],
                                     [1.7699, 0.4926, 0.0519],
                                     [1.7416, 0.4820, 0.0512]
                                     ])
varying_decoders_trainset = np.array([[0.5193, 0.8788, 0.0150],
                                      [0.6867, 0.7572, 0.0254],
                                      [0.8601, 0.6821, 0.0311],
                                      [0.9154, 0.6529, 0.0325],
                                      [1.0038, 0.6114, 0.0357]
                                      ])

# Create a 1x2 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), varying_encoders_testset[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), varying_encoders_trainset[:, 1], color='blue', label='Training set')
# Set the tick locations on the x-axis for the first plot
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of encoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), varying_encoders_testset[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), varying_encoders_trainset[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of encoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), varying_decoders_testset[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), varying_decoders_trainset[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of decoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), varying_decoders_testset[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), varying_decoders_trainset[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of decoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

"""#### Using text-to-text for hyperparameter estimation."""

def split_test_multiplication_t2t(splits = np.linspace(0.1, 0.9, 9),
                                  test_hyperparams: float = False,
                                  eval: float = False, batch_sizes = [32, 64, 128, 256],
                                  epochs = [20, 30, 40]):

  if test_hyperparams:
    print("Starting test for hyperparameters and splits.")
    results = []
    for i in splits:
      # Create training and test sets
      X_train, X_test, y_train, y_test = train_test_split(X_text_onehot_mult, y_text_onehot_mult, train_size=i)

      # Go over hyperparameters
      for batch in batch_sizes:
        for epoch_num in epochs:
          print(f"Now testing split {i = }, batch size {batch}, epoch num {epoch_num}")
          # Initialize model
          T2T = build_text2text_mult_model(show_summary=False, max_answer_length=5)
          # Fit model
          history = T2T.fit(X_train, y_train, batch_size=batch, validation_split=1-i,
                            epochs=epoch_num, verbose=0, shuffle=True)

          # Get the accuracy and validation accuracy
          Train_acc = history.history['accuracy']
          Test_acc = history.history['val_accuracy']

          # Append train test acc and corresponding batch size and number of epochs
          results.append([Train_acc, Test_acc, {'batch': batch,
                                                'Epoch num': epoch_num,
                                                'split size': i}])

          # Evaluate model
          if eval:
            T2T.evaluate(X_test, y_test)

    return results

result_hyperparam_multiplication_t2t = split_test_multiplication_t2t(splits = [0.25, 0.5, 0.75, 0.9],
                                                                      test_hyperparams=True,
                                                                      batch_sizes = [32, 64, 128],
                                                                      epochs = [10, 20, 30])

top5_mult2, best_mult2 = find_top_5(result_hyperparam_multiplication_t2t)
# Create a DataFrame
df2 = pd.DataFrame(top5_mult2,
                   columns=['training accuracy per epoch', 'testing accuracy per epoch', 'hyperparameters'])

# Display the DataFrame
print(df2)

"""Best model"""

df2.iloc[0]

plt.plot(np.arange(1, 30+1), df2.iloc[0][0], label='Training', color='blue')
plt.plot(np.arange(1, 30+1), df2.iloc[0][1], label='Testing', color='red')
plt.grid()
plt.ylabel("Accuracy")
plt.xlabel("Epochs")
plt.legend()
plt.show()

"""#### Check the combinations of number of encoder and decoders for text-to-text."""

def test_num_decode_encode_multiplication(num_of_decodes = [1,2,3,4,5],
                                          num_of_encodes = [1,2,3,4,5]):

  X_train, X_test, y_train, y_test = train_test_split(X_text_onehot_mult, y_text_onehot_mult, train_size=0.9)
  for i in num_of_decodes:
    for j in num_of_encodes:
      with strategy.scope():
        print(f"Testing {i} decode, {j} encode layers")

        model = build_text2text_mult_model(show_summary=False, max_answer_length=5,
                                     num_encode_layers=j, num_decode_layers=i,  metrics=['accuracy','mse'])
        model.fit(X_train,y_train,batch_size=32,validation_split=0.1,epochs=30, verbose=0)
        print("\nResult - test set:")
        model.evaluate(X_test,y_test)
        print("\nResult - training set")
        model.evaluate(X_train,y_train)

print("Using 1 decoder and varying encoders.")
test_num_decode_encode_multiplication(num_of_decodes = [1],
                                      num_of_encodes = [1,2,3,4,5])
print("Using 1 encoder and varying decoders.")
test_num_decode_encode_multiplication(num_of_decodes = [1,2,3,4,5],
                                      num_of_encodes = [1])

"""Create data from printed outputs"""

# Results for varying encoders. # Column 0: loss, Column 1: accuracy, Column 2: MSE
T2T_varying_encoders_testset = np.array([[0.4040, 0.8474, 0.0165],
                                        [0.3847, 0.8526, 0.0163],
                                        [0.4703, 0.8202, 0.0196],
                                        [0.5927, 0.7704, 0.0236],
                                        [0.6368, 0.7454, 0.0257]
                                        ])

T2T_varying_encoders_trainset = np.array([[0.2207, 0.9288, 0.0089],
                                          [0.1652, 0.9492, 0.0067],
                                          [0.2034, 0.9376, 0.0082],
                                          [0.3581, 0.8735, 0.0146],
                                          [0.4128, 0.8504, 0.0169]
                                          ])

# Results for varying decoders. # Column 0: loss, Column 1: accuracy, Column 2: MSE
T2T_varying_decoders_trainset = np.array([[0.2474, 0.9212, 0.0100],
                                          [0.3329, 0.8801, 0.0135],
                                          [0.3238, 0.8750, 0.0138],
                                          [0.4753, 0.8178, 0.0190],
                                          [0.5236, 0.7942, 0.0202]
                                          ])
T2T_varying_decoders_testset = np.array([[0.4148, 0.8364, 0.0169],
                                         [0.4119, 0.8336, 0.0167],
                                         [0.4124, 0.8336, 0.0174],
                                         [0.5352, 0.7880, 0.0212],
                                         [0.5728, 0.7690, 0.0219],
                                         ])


# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_testset[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_trainset[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of encoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_testset[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_encoders_trainset[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of encoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

# Create a 2x1 subplot
fig, axes = plt.subplots(2, 1, figsize=(6, 8))

# Plot for Test set accuracy
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_testset[:, 1], color='red', label='Test set')
axes[0].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_trainset[:, 1], color='blue', label='Training set')
axes[0].set_xticks(np.arange(1, 6, 1))
axes[0].set_xlabel("Number of decoding layers")
axes[0].set_ylabel("Accuracy")
axes[0].grid()

# Plot for Test set mean-squared error
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_testset[:, 2], color='red', label='Test set')
axes[1].plot(np.arange(1, 5+1, 1), T2T_varying_decoders_trainset[:, 2], color='blue', label='Training set')
axes[1].set_xticks(np.arange(1, 6, 1))
axes[1].set_xlabel("Number of decoding layers")
axes[1].set_ylabel("Mean-squared error")
axes[1].grid()

# Adjust layout
plt.tight_layout()
plt.legend()

# Show the plot
plt.show()

